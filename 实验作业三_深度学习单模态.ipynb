{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9fda4c-4d10-44b0-86d9-0187ae18ed6a",
   "metadata": {},
   "source": [
    "### 使用BertTokenizer进行文本向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3061bfb7-790b-40e4-84a5-21777e581d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eda0a5-9aea-4c99-b3ea-a90cf4d4c962",
   "metadata": {},
   "source": [
    "## 1、构造文本特征提取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "037185c3-14fb-48b7-894e-8870d1786124",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 文本向量化函数\n",
    "## text_list 文本内容的list\n",
    "## 返回一个字典，{'input_ids':value, 'token_type_ids':value, 'attention_mask':value},每个元素的长度等于len(text_list)\n",
    "## \"input_ids\"-词转换为数字后的序列 'token_type_ids'-标记一段文本中不同句子的序号 'attention_mask'-标记填充位置的序号 \n",
    "## reference: https://huggingface.co/docs/transformers/main/en/glossary\n",
    "def text_tokenize(text_list): \n",
    "    tokenizer = BertTokenizer.from_pretrained('./bert-base-uncased',do_lower_case=True)\n",
    "    encoded_text = tokenizer.batch_encode_plus(\n",
    "        text_list,\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=256,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return encoded_text\n",
    "## 'input_ids' 'token_type_ids' 'attention_mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8244820c-61db-4956-ac2a-70826f38f63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'> 3 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 文本向量化示例\n",
    "temp_txt_list = [\"Hello,my name is Jerry.\",\"Hello,my name is Tom.\"]\n",
    "temp_coded_txt = text_tokenize(temp_txt_list)\n",
    "print(type(temp_coded_txt),len(temp_coded_txt),len(temp_coded_txt[\"input_ids\"]))\n",
    "len(temp_coded_txt[\"token_type_ids\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1406f0d-5ecc-489d-9395-46818f35961c",
   "metadata": {},
   "source": [
    "## 2、读入CSV文件示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2996d3bc-d357-4668-a624-a76d3f4fe372",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读入csv文件示例\n",
    "## 由于我们的csv文件使用\"#\"分隔，需要定义sep参数为\"#\",否则会读取失败！！！\n",
    "train_csv = pd.read_csv(\"./CSVfile/train.csv\",sep=\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f05c3893-b7e7-44e1-b724-ce3f8b2d2540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Excuse me.'"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.text.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "743c4b1c-beb9-4802-8ad4-eaff49fa7f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ses01F_impro01_F000</td>\n",
       "      <td>train/Ses01F_impro01_F000.wav</td>\n",
       "      <td>Excuse me.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ses01F_impro01_F001</td>\n",
       "      <td>train/Ses01F_impro01_F001.wav</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ses01F_impro01_F002</td>\n",
       "      <td>train/Ses01F_impro01_F002.wav</td>\n",
       "      <td>Is there a problem?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ses01F_impro01_F005</td>\n",
       "      <td>train/Ses01F_impro01_F005.wav</td>\n",
       "      <td>Well what's the problem?  Let me change it.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ses01F_impro01_F012</td>\n",
       "      <td>train/Ses01F_impro01_F012.wav</td>\n",
       "      <td>That's out of control.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num                   id                           path  \\\n",
       "0    1  Ses01F_impro01_F000  train/Ses01F_impro01_F000.wav   \n",
       "1    2  Ses01F_impro01_F001  train/Ses01F_impro01_F001.wav   \n",
       "2    3  Ses01F_impro01_F002  train/Ses01F_impro01_F002.wav   \n",
       "3    4  Ses01F_impro01_F005  train/Ses01F_impro01_F005.wav   \n",
       "4    5  Ses01F_impro01_F012  train/Ses01F_impro01_F012.wav   \n",
       "\n",
       "                                          text  label  \n",
       "0                                   Excuse me.      2  \n",
       "1                                        Yeah.      2  \n",
       "2                          Is there a problem?      2  \n",
       "3  Well what's the problem?  Let me change it.      2  \n",
       "4                       That's out of control.      0  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 快速查看前5条数据\n",
    "train_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b5ab3872-3da8-4f5f-9331-b72a4ddbd472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    1066\n",
       "1     891\n",
       "3     696\n",
       "0     606\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 统计该csv下lable列不同值的数量\n",
    "train_csv.value_counts(subset=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "3d370b09-9821-4109-991c-493c0954b27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Train dataset sample distribution')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 画图显示类别数\n",
    "plt.bar([0,1,2,3],list(train_csv.value_counts(subset=\"label\")),tick_label = [\"0\",\"1\",\"2\",\"3\"])\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Num\")\n",
    "plt.title(\"Train dataset sample distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed34abe-0e67-425a-9062-63caa57a3f90",
   "metadata": {},
   "source": [
    "## 3、读取CSV文件、分离文件路径、文本内容、标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1c77b828-131d-46af-8dfb-ef006ab58617",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取train.csv、dev.csv\n",
    "train_csv = pd.read_csv(\"./CSVfile/train.csv\", sep = \"#\")\n",
    "dev_csv = pd.read_csv(\"./CSVfile/dev.csv\", sep = \"#\")\n",
    "## 分离文件路径、文本内容和标签\n",
    "## 训练时间较长，建议可以先截取部分样本进行代码正确性验证，再使用全部样本\n",
    "train_path = list(train_csv.path)[:1500]\n",
    "train_label = list(train_csv.label)[:1500]\n",
    "train_txt = list(train_csv.text)[:1500]\n",
    "dev_path = list(dev_csv.path)[:500]\n",
    "dev_label = list(dev_csv.label)[:500]\n",
    "dev_txt = list(dev_csv.text)[:500]\n",
    "\n",
    "# train_path = list(train_csv.path)\n",
    "# train_label = list(train_csv.label)\n",
    "# train_txt = list(train_csv.text)\n",
    "# dev_path = list(dev_csv.path)\n",
    "# dev_label = list(dev_csv.label)\n",
    "# dev_txt = list(dev_csv.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf605b1d-02c1-4170-9f20-2c1fbd2c5fa9",
   "metadata": {},
   "source": [
    "## 4、创建Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "884d5b66-08ad-41ab-8d97-5e8bf58554fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 500\n"
     ]
    }
   ],
   "source": [
    "##  'input_ids' 'token_type_ids' 'attention_mask'\n",
    "train_coded_txt = text_tokenize(train_txt)\n",
    "dev_coded_txt = text_tokenize(dev_txt)\n",
    "train_dataset = TensorDataset(train_coded_txt[\"input_ids\"], \n",
    "                              train_coded_txt[\"attention_mask\"],\n",
    "                              torch.tensor(train_label))\n",
    "dev_dataset = TensorDataset(dev_coded_txt[\"input_ids\"], \n",
    "                            dev_coded_txt[\"attention_mask\"],\n",
    "                            torch.tensor(dev_label))\n",
    "print(len(train_dataset),len(dev_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9543205c-c791-4c6e-854b-3259fa157d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "255e8a1b-4acb-4635-ad08-91d1484bfa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 这里的batch_size 可以从1、2、4、8、16...尝试，过大的batch_size会使训练过程因为显存不足失败\n",
    "batch_size = 64\n",
    "dataloader_train = DataLoader(\n",
    "    train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size\n",
    ")\n",
    "dataloader_dev = DataLoader(\n",
    "    dev_dataset, sampler=RandomSampler(dev_dataset), batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b55df-78fe-4b32-aaff-fb9884d5eb01",
   "metadata": {},
   "source": [
    "## 5、定义性能指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "f7bf52fb-ddab-448c-9470-a73e4ba69841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "47c38fca-365c-4508-a6a3-712f612d40b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "48d689ef-f77c-476d-b004-5a88644761db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {0:\"angry\",1:\"happy or excited\",2:\"neutral\",3:\"sad\"}\n",
    "    # print(preds)\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "76deef61-cee4-4074-ae9d-af2e6050e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "02602577-f76d-4c08-ba66-be8feddecb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_classification(preds, labels, average_f1='macro'):  # weighted, macro\n",
    "    preds = np.argmax(preds, axis=1).flatten()\n",
    "    labels = labels.flatten()\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=average_f1, zero_division=0)\n",
    "    precision = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    ua = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    confuse_matrix = confusion_matrix(labels, preds)\n",
    "    return accuracy, ua, f1, precision, confuse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb1bd0-dee0-4401-a8c7-d96c7bad44d5",
   "metadata": {},
   "source": [
    "## 6、设置模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "1b9e9e08-f3ad-4d2f-8de9-4e7b21f6882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "f920957a-b873-4047-a011-ac2c6fdc0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDLmodel:\n",
    "    def __init__(self, model, device, patience=3):\n",
    "        self.device = device\n",
    "        self.patience = patience\n",
    "        self.best_f1_score = 0\n",
    "        self.early_stop_counter = 0\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(f\"Using {torch.cuda.device_count()} GPUs.\")\n",
    "            self.model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = AdamW(\n",
    "            self.model.parameters(), lr=5e-5, eps=1e-8, weight_decay=0.05\n",
    "        )\n",
    "        self.scheduler = None\n",
    "\n",
    "    def train(self, dataloader_train, dataloader_dev, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            for batch in tqdm(dataloader_train, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                batch = tuple(t.to(self.device) for t in batch)\n",
    "                input_ids, attention_mask, labels = batch\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "                )\n",
    "\n",
    "                loss = outputs.loss.mean()\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            avg_train_loss = total_loss / len(dataloader_train)\n",
    "            print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "            val_loss, val_f1 = self.evaluate(dataloader_dev)\n",
    "\n",
    "            if val_f1 > self.best_f1_score:\n",
    "                self.best_f1_score = val_f1\n",
    "                self.early_stop_counter = 0\n",
    "                torch.save(self.model.state_dict(), \"best_model.pt\")\n",
    "                print(\"F1 Score increased, saving model.\\n\")\n",
    "            else:\n",
    "                self.early_stop_counter += 1\n",
    "                print(\n",
    "                    f\"No improvement in F1 Score for {self.early_stop_counter} epoch(s).\\n\"\n",
    "                )\n",
    "                if self.early_stop_counter >= self.patience:\n",
    "                    print(\n",
    "                        f\"Early stopping triggered at F1 Score: {self.best_f1_score:.4f}\"\n",
    "                    )\n",
    "                    break\n",
    "\n",
    "    def evaluate(self, dataloader_val):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader_val:\n",
    "                batch = tuple(t.to(self.device) for t in batch)\n",
    "                input_ids, attention_mask, labels = batch\n",
    "\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "                )\n",
    "\n",
    "                loss = outputs.loss.mean()\n",
    "                logits = outputs.logits\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = total_loss / len(dataloader_val)\n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "        print(\n",
    "            f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\"\n",
    "        )\n",
    "\n",
    "        return avg_val_loss, f1\n",
    "\n",
    "    def predict(self, dataloader_test):\n",
    "        self.model.eval()\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "            print(\"Loaded best model for prediction.\")\n",
    "        except:\n",
    "            print(\"No saved model found, using current model for prediction.\")\n",
    "\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader_test:\n",
    "                batch = tuple(t.to(self.device) for t in batch)\n",
    "                input_ids, attention_mask = batch\n",
    "\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "fec75a77-4152-49ab-9cc4-4433fdbacd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "## 设置随机种子\n",
    "def set_seeds(seed_val):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "af464655-26d5-43e1-89a0-29bda65bf7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test_preds 长度为1241的list，对应测试集中1241个样本的标签\n",
    "##运行后会在当前目录生成result.csv文件，提交result.csv文件即可\n",
    "##如果没有生成，请检查test_preds的长度是否为1241！\n",
    "def write_result(test_preds):\n",
    "    if len(test_preds) != 1241:\n",
    "        print(\"错误！请检查test_preds长度是否为1241！！！\")\n",
    "        return -1\n",
    "    test_csv = pd.read_csv(\"./CSVfile/test.csv\",sep=\"#\")\n",
    "    test_csv[\"label\"] = test_preds\n",
    "    test_csv.to_csv(\"./result.csv\",sep = \"#\")\n",
    "    print(\"测试集预测结果已成功写入到文件中！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6cefe5b8-71e0-4a1a-bdae-a6673b02edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "3f388d7c-9451-462b-8fac-6c49ee431ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Using 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 24/24 [00:12<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2388\n",
      "Validation Loss: 1.2513, Accuracy: 0.4300, F1 Score: 0.3996\n",
      "F1 Score increased, saving model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 24/24 [00:12<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.8841\n",
      "Validation Loss: 1.2371, Accuracy: 0.5220, F1 Score: 0.5173\n",
      "F1 Score increased, saving model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 24/24 [00:13<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5713\n",
      "Validation Loss: 1.1102, Accuracy: 0.6140, F1 Score: 0.6158\n",
      "F1 Score increased, saving model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 24/24 [00:12<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3301\n",
      "Validation Loss: 1.1426, Accuracy: 0.6040, F1 Score: 0.5980\n",
      "No improvement in F1 Score for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 24/24 [00:12<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2289\n",
      "Validation Loss: 1.3522, Accuracy: 0.6080, F1 Score: 0.6023\n",
      "No improvement in F1 Score for 2 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 24/24 [00:12<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1703\n",
      "Validation Loss: 1.4373, Accuracy: 0.6240, F1 Score: 0.6285\n",
      "F1 Score increased, saving model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 24/24 [00:13<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1391\n",
      "Validation Loss: 1.3443, Accuracy: 0.6420, F1 Score: 0.6319\n",
      "F1 Score increased, saving model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 24/24 [00:12<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1218\n",
      "Validation Loss: 1.3085, Accuracy: 0.6500, F1 Score: 0.6400\n",
      "F1 Score increased, saving model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 24/24 [00:12<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0986\n",
      "Validation Loss: 1.5060, Accuracy: 0.6420, F1 Score: 0.6420\n",
      "F1 Score increased, saving model.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 24/24 [00:12<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0948\n",
      "Validation Loss: 1.4932, Accuracy: 0.6320, F1 Score: 0.6277\n",
      "No improvement in F1 Score for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 24/24 [00:13<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0918\n",
      "Validation Loss: 1.5832, Accuracy: 0.6500, F1 Score: 0.6357\n",
      "No improvement in F1 Score for 2 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 24/24 [00:12<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0961\n",
      "Validation Loss: 1.6818, Accuracy: 0.6060, F1 Score: 0.6027\n",
      "No improvement in F1 Score for 3 epoch(s).\n",
      "\n",
      "Early stopping triggered at F1 Score: 0.6420\n"
     ]
    }
   ],
   "source": [
    "# model reference： https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification\n",
    "set_seeds(17)\n",
    "pretrained_model = pretrained_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"./bert-base-uncased\",\n",
    "    num_labels=4,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "mymodel = MyDLmodel(pretrained_model, device)\n",
    "epochs = 15\n",
    "mymodel.train(dataloader_train, dataloader_dev, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "dea31408-75f8-4e1f-bf0a-dde019047b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 预测测试集标签\n",
    "# test_csv = pd.read_csv(\"./CSVfile/test.csv\",sep = \"#\")\n",
    "# test_text = list(test_csv.text)\n",
    "# test_coded_txt = text_tokenize(test_text)\n",
    "# test_dataset = TensorDataset(\n",
    "#     test_coded_txt[\"input_ids\"], \n",
    "#     test_coded_txt[\"attention_mask\"])\n",
    "# dataloader_test = DataLoader(\n",
    "#     test_dataset,\n",
    "#     sampler=RandomSampler(test_dataset),\n",
    "#     batch_size=32)\n",
    "# test_preds = mymodel.predict(dataloader_test)\n",
    "# ## 写入预测结果\n",
    "# write_result(test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
